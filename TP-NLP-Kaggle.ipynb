{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico NLP - ECI 2019\n",
    "\n",
    "#### Alumno: Leandro Carreira\n",
    "#### LU: 669/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se detalla a continuación el proceso usado para alcanzar el resultado de **66.168%** de acierto en el dataset Natural Language Inference (SNLI) en la competencia ECI 2019 - NLP:\n",
    "\n",
    "https://www.kaggle.com/c/eci2019nlp/overview\n",
    "\n",
    "Se redujo el modelo a lo **mínimo y necesario** usando fastai con **embeddings de dimensión 2** y **10 iteraciones**, alcanzando resultados similares a los del paper de [Gururangan et al., 2018](https://www.aclweb.org/anthology/N18-2017) que demuestran que existe un sesgo en el dataset SNLI que permite predecir las etiquetas de las hipótesis sin necesidad de usar las premisas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:00:19.325915Z",
     "start_time": "2019-08-01T19:00:19.317273Z"
    }
   },
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings\n",
    "import re\n",
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Given a text, cleans and normalizes it.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Replace ips\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', s)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:00:19.494444Z",
     "start_time": "2019-08-01T19:00:19.443645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data succesfully loaded.\n",
      "Test data succesfully loaded.\n",
      "Validation data succesfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# From read_data.py\n",
    "import json\n",
    "import csv\n",
    "\n",
    "fasttext_train_data_dir = './data.train.txt'\n",
    "fasttext_train_data_no_labels_dir = './data.train.no.labels.txt'\n",
    "\n",
    "fasttext_test_data_dir = './data.test.txt'\n",
    "fasttext_val_data_dir = './data.val.txt'\n",
    "\n",
    "train_sentences_dir = './snli_1.0_train_filtered.jsonl'\n",
    "train_labels_dir    = './snli_1.0_train_gold_labels.csv'\n",
    "\n",
    "val_sentences_dir = './snli_1.0_dev_filtered.jsonl'\n",
    "val_labels_dir    = './snli_1.0_dev_gold_labels.csv'\n",
    "\n",
    "test_sentences_dir  = './snli_1.0_test_filtered.jsonl'\n",
    "\n",
    "\n",
    "def create_data(sentences_dir, labels_dir=None, data_dir=None):\n",
    "    try:\n",
    "        # Loading sentences from file\n",
    "        sentences_data = open(sentences_dir, 'r')\n",
    "    except:\n",
    "        print('Error loading sentences at: {}'.format(sentences_dir))\n",
    "        return\n",
    "    \n",
    "    if labels_dir:\n",
    "        try:\n",
    "            # Loading labels from file\n",
    "            label_data = open(labels_dir, 'r')\n",
    "        except:\n",
    "            print('Error loading labels at: {}'.format(labels_dir))\n",
    "            return\n",
    "        # Append-adds at last \n",
    "        fasttext_data = open(data_dir, \"a\") # append mode \n",
    "        for sentence, label in zip(it_sentences(sentences_data), it_labels(label_data)):\n",
    "            # Tenemos la oración en sentence con su categoría en label\n",
    "            #print('[{}]: {}'.format(label, sentence))\n",
    "            fasttext_data.write('__label__{} {}\\n'.format(label, normalize(sentence)))\n",
    "            pass\n",
    "        fasttext_data.close()\n",
    "    else:\n",
    "        fasttext_data = open(data_dir, \"a\") # append mode \n",
    "        for sentence in it_sentences(sentences_data):\n",
    "            # Tenemos una oración en sentence\n",
    "            #print('{}'.format(sentence))\n",
    "            fasttext_data.write('{}\\n'.format(normalize(sentence)))\n",
    "            pass\n",
    "        fasttext_data.close()\n",
    "        try:\n",
    "            # Loading sentences from file\n",
    "            sentences_data = open(sentences_dir, 'r')\n",
    "        except:\n",
    "            print('Error loading sentences at: {}'.format(sentences_dir))\n",
    "            return\n",
    "        fasttext_data = open(data_dir[:-4]+'.pair_id.txt', \"a\") # append mode \n",
    "        for sentence in it_pairid(sentences_data):\n",
    "            # Tenemos una oración en sentence\n",
    "            #print('{}'.format(sentence))\n",
    "            fasttext_data.write('{}\\n'.format(sentence))\n",
    "            pass\n",
    "        fasttext_data.close()\n",
    "    \n",
    "def it_sentences(sentence_data):\n",
    "    for line in sentence_data:\n",
    "        example = json.loads(line)\n",
    "        yield example['sentence2']\n",
    "\n",
    "def it_pairid(sentence_data):\n",
    "    for line in sentence_data:\n",
    "        example = json.loads(line)\n",
    "        yield example['pairID']        \n",
    "\n",
    "def it_labels(label_data):\n",
    "    label_data_reader = csv.DictReader(label_data)\n",
    "    for example in label_data_reader:\n",
    "        yield example['gold_label']\n",
    "\n",
    "# For training\n",
    "try:\n",
    "    data = open(fasttext_train_data_dir, 'r')\n",
    "    print('Training data succesfully loaded.')\n",
    "except IOError:\n",
    "    print('Training data not found. Creating new one... ')\n",
    "    create_data(train_sentences_dir, train_labels_dir, data_dir=fasttext_train_data_dir)\n",
    "    print('Done.')\n",
    "\n",
    "# For unsupervised learning (no labels)\n",
    "# try:\n",
    "#     data = open(fasttext_train_data_no_labels_dir, 'r')\n",
    "#     print('Training data 2 succesfully loaded.')\n",
    "# except IOError:\n",
    "#     print('Training data 2 not found. Creating new one... ')\n",
    "#     create_data(train_sentences_dir, data_dir=fasttext_train_data_no_labels_dir)\n",
    "#     print('Done.')\n",
    "    \n",
    "# For test\n",
    "try:\n",
    "    data = open(fasttext_test_data_dir, 'r')\n",
    "    print('Test data succesfully loaded.')\n",
    "except IOError:\n",
    "    print('Test data not found. Creating new one... ')\n",
    "    create_data(test_sentences_dir, data_dir=fasttext_test_data_dir)\n",
    "    print('Done.')\n",
    "    \n",
    "# For validation\n",
    "try:\n",
    "    data = open(fasttext_val_data_dir, 'r')\n",
    "    print('Validation data succesfully loaded.')\n",
    "except IOError:\n",
    "    print('Validation data not found. Creating new one... ')\n",
    "    create_data(val_sentences_dir, val_labels_dir, data_dir=fasttext_val_data_dir)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:00:19.805164Z",
     "start_time": "2019-08-01T19:00:19.573993Z"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-30T13:44:07.964Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "                                  lr = 1.0,\n",
    "                                  epoch = 250,\n",
    "                                  wordNgrams = 2,\n",
    "                                  bucket = 200000,\n",
    "                                  dim = 50,\n",
    "                                  loss = 'hs',\n",
    "                                  thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T12:33:22.378537Z",
     "start_time": "2019-07-31T12:33:20.131660Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "model.save_model(\"model_filename.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:58:20.408708Z",
     "start_time": "2019-07-30T03:58:20.405485Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = fasttext.load_model(\"model_filename.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:06:23.141310Z",
     "start_time": "2019-08-01T19:06:23.132945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario de 29805 palabras\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulario de {} palabras'.format(len(model.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:06:23.151440Z",
     "start_time": "2019-08-01T19:06:23.144287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "['__label__entailment', '__label__contradiction', '__label__neutral']\n"
     ]
    }
   ],
   "source": [
    "print('Labels:')\n",
    "print(model.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets find good hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** FastText no brinda mucha flexibilidad a la hora de entrenar modelos, por lo que por cada variante de los hiperparámetros, deberá entrenarse un nuevo modelo desde cero.\n",
    "\n",
    "Tampoco tenemos la posibilidad de testear el modelo a mitad de entrenamiento usando el validation set, por lo que solo al final del entrenamiento podemos calificarlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando *wordNgrams*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:22:04.148333Z",
     "start_time": "2019-08-01T17:17:18.509786Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 5,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T12:33:28.175843Z",
     "start_time": "2019-07-31T12:33:27.614368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9842, 0.7291200975411501, 0.7291200975411501)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test('./data.val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:25:53.385059Z",
     "start_time": "2019-08-02T12:25:53.202670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.653\n",
      "R@1\t0.653\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:34:07.368201Z",
     "start_time": "2019-08-01T17:32:01.402992Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:34:07.390413Z",
     "start_time": "2019-08-01T17:34:07.369748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:34:07.400357Z",
     "start_time": "2019-08-01T17:34:07.392471Z"
    }
   },
   "source": [
    "#### n-grams: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:40:06.145930Z",
     "start_time": "2019-08-01T17:36:56.411452Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 2,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:40:06.171967Z",
     "start_time": "2019-08-01T17:40:06.147567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.630\n",
      "R@1\t0.630\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:43:50.378620Z",
     "start_time": "2019-08-01T17:40:06.173209Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 3,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:43:50.415184Z",
     "start_time": "2019-08-01T17:43:50.381081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.604\n",
      "R@1\t0.604\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:48:11.955650Z",
     "start_time": "2019-08-01T17:43:50.416827Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 4,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:48:11.988821Z",
     "start_time": "2019-08-01T17:48:11.957297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.576\n",
      "R@1\t0.576\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis:\n",
    "\n",
    "Con *wordNgrams=1* se obtuvieron los mejores resultados.\n",
    "\n",
    "\n",
    "Probemos con diferentes **tamaños de embeddings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando tamaño de Embeddings\n",
    "\n",
    "> *More is less*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 10 (2^10=1024 representaciones no parece \"poco\" para este problema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:50:10.680313Z",
     "start_time": "2019-08-01T17:48:11.990325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.648\n",
      "R@1\t0.648\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 10,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:52:19.304613Z",
     "start_time": "2019-08-01T17:50:10.682205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:54:51.632657Z",
     "start_time": "2019-08-01T17:52:19.306248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.648\n",
      "R@1\t0.648\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 50,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:58:06.471652Z",
     "start_time": "2019-08-01T17:54:51.634086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.647\n",
      "R@1\t0.647\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 100,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T18:03:04.233892Z",
     "start_time": "2019-08-01T17:58:06.473001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.566\n",
      "R@1\t0.566\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 200,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same pero con más iteraciones (para ser justos con embeddings más grandes)\n",
    "\n",
    "#### n-grams: 1\n",
    "#### embedding size: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T18:13:06.875783Z",
     "start_time": "2019-08-01T18:05:17.815184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 2000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 10,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T18:21:10.041898Z",
     "start_time": "2019-08-01T18:13:06.877889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.648\n",
      "R@1\t0.648\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 2000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 20,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T18:31:36.454417Z",
     "start_time": "2019-08-01T18:21:10.043519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 2000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 50,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T18:44:16.252137Z",
     "start_time": "2019-08-01T18:31:36.456247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.574\n",
      "R@1\t0.574\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 2000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 100,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-01T18:53:50.980Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 2000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 200,\n",
    "              loss = 'softmax',\n",
    "              thread=1)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))\n",
    "\n",
    "# me queda chica la compu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams: 1\n",
    "#### embedding size: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:29:18.623455Z",
     "start_time": "2019-08-01T19:14:33.278866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 5000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 5,\n",
    "              loss = 'softmax',\n",
    "              thread=8)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # *Supervivencia del más apto*\n",
    ">\n",
    "> # *Sobresaliencia del más simple*\n",
    ">\n",
    "> what-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding de dimensión 1 (2 valores posibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T20:01:44.578277Z",
     "start_time": "2019-08-01T19:47:42.493169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.506\n",
      "R@1\t0.506\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 5000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 1,\n",
    "              loss = 'softmax',\n",
    "              thread=8)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Razonando (superficialmente) resultados\n",
    "\n",
    "Acierta con un 50% de probabilidades, pero considerando que son 3 categorías bien repartidas, estamos bastante por encima de los 33.33% de una respuesta al azar.\n",
    "\n",
    "Si puede representar solo dos valores, podría \"categorizar\" la palabra en una u otra categoría, pero como solo existen dos valores posibles (0 y 1), no será posible corresponder a las 3 categorías del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding de dimensión 2 (2^2 valores posibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T20:16:25.480999Z",
     "start_time": "2019-08-01T20:01:44.583747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 5000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=8)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Razonando (superficialmente) resultados\n",
    "\n",
    "En este caso, un embedding de dimensión 2 puede representar 4 elementos, por lo que podria haber una correspondencia directa entre cada embedding (de cada palabra) y la categoria \"asociada\".\n",
    "\n",
    "Si cada palabra tiene un sesgo hacia alguna de las categorias ( ej. es más usada en '*contradicciones*'), **aportará información favorable** para la categoria correspondiente al ser usada en el **promedio** a calcular para la oración.\n",
    "\n",
    "Para palabras comunes podría usar una 4ta categoria que da la misma probabilidad a las 3, y para palabras sesgadas, debería elegir entre alguno de los otros 3 valores posibles (**(0,0)**, **(0,1)** y **(1,0)**, ó **(1,1)** para la 4ta categoria).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding de dimensión 3 (2^3 valores posibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T20:31:00.802030Z",
     "start_time": "2019-08-01T20:16:25.484163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 5000,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 3,\n",
    "              loss = 'softmax',\n",
    "              thread=8)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Razonando (superficialmente) resultados\n",
    "\n",
    "No se observan mejoras por sobre dimensión 2, a pesar de que pueda representar 8 valores en total con sus embeddings, el doble que antes.\n",
    "\n",
    "Ésto indica que es suficiente con embeddings de dos dimensiones para capturar el sesgo de cada palabra (aunque ignorando otra posible información)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solo queda ver si quedó alguna palabra fuera del bucket, o si puede hacerse algo mejor con más epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T00:00:20.643309Z",
     "start_time": "2019-08-02T00:00:20.613724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario de 29805 palabras\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulario de {} palabras'.format(len(model.words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vocabulario es de menos de 30.000 palabras, por lo que el bucket usado hasta el momento de 200.000 palabras es más que suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T00:00:20.610332Z",
     "start_time": "2019-08-01T21:01:26.840883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.647\n",
      "R@1\t0.647\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 50000,    # x10\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:27:12.480334Z",
     "start_time": "2019-08-02T01:27:09.209259Z"
    }
   },
   "source": [
    "Se ven indicios de overfitting, reduzco epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T01:34:17.249596Z",
     "start_time": "2019-08-02T01:30:48.552728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 1000,   \n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T02:15:55.261255Z",
     "start_time": "2019-08-02T02:14:16.538926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 500,   \n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T02:16:46.057498Z",
     "start_time": "2019-08-02T02:15:55.263361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 250,   \n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T02:41:00.201420Z",
     "start_time": "2019-08-02T02:40:40.334675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 100,   \n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T02:41:18.536863Z",
     "start_time": "2019-08-02T02:41:08.311048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.649\n",
      "R@1\t0.649\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 50,   \n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:15:36.607266Z",
     "start_time": "2019-08-02T12:15:34.009776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences\t9842\n",
      "P@1\t0.652\n",
      "R@1\t0.652\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 10,   \n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000, \n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "Se decide utilizar el modelo más simple de embeddings de 2 dimensiones que demuestra el gran sesgo en el training set que permite predecir resultados con más del 65% de acierto, mientras que al azar serían del 33%, con un simple modelo entrenado en pocos segundos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando modelo con toda la data (train + validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:39:26.293107Z",
     "start_time": "2019-08-02T12:39:23.524794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos resultados NO generalizan, ya que evalúa con la misma data de entrenamiento:\n",
      "Total sentences\t9842\n",
      "P@1\t0.668\n",
      "R@1\t0.668\n"
     ]
    }
   ],
   "source": [
    "fasttext_train_ALL_data_dir = './data.train+val.txt'\n",
    "\n",
    "model = fasttext.train_supervised(fasttext_train_ALL_data_dir,\n",
    "              lr = 1.0,\n",
    "              epoch = 10,\n",
    "              wordNgrams = 1,\n",
    "              bucket = 200000,\n",
    "              dim = 2,\n",
    "              loss = 'softmax',\n",
    "              thread=4)\n",
    "\n",
    "print('Estos resultados NO generalizan, ya que evalúa con la misma data de entrenamiento:')\n",
    "def print_results(N, p, r):\n",
    "    print(\"Total sentences\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.val.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T05:21:12.765588Z",
     "start_time": "2019-07-30T05:21:12.705297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['__label__contradiction']], array([[1.00001979]]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['the kids are frowning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T05:21:13.069208Z",
     "start_time": "2019-07-30T05:21:13.057288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['__label__contradiction']], array([[0.99987841]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['the kids are frown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:14:50.659052Z",
     "start_time": "2019-08-01T17:14:50.504456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data succesfully loaded.\n",
      "\n",
      "the church has cracks in the ceiling . \n",
      "Category: contradiction\n",
      "Prob: [9.99913692e-01 1.16334704e-04]\n",
      "('__label__contradiction', '__label__entailment')\n",
      "\n",
      "the church is filled with song . \n",
      "Category: neutral\n",
      "Prob: [0.93546563 0.06456374]\n",
      "('__label__neutral', '__label__entailment')\n",
      "\n",
      "a choir singing at a baseball game . \n",
      "Category: entailment\n",
      "Prob: [0.57135916 0.24671638 0.18195307]\n",
      "('__label__entailment', '__label__contradiction', '__label__neutral')\n",
      "\n",
      "the woman is young . \n",
      "Category: neutral\n",
      "Prob: [0.37215713 0.35436693 0.27351052]\n",
      "('__label__neutral', '__label__contradiction', '__label__entailment')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_data = open(fasttext_test_data_dir, 'r')\n",
    "    print('Validation data succesfully loaded.')\n",
    "except IOError:\n",
    "    print('Validation data not found.')\n",
    "\n",
    "print()\n",
    "for i, sentence in enumerate(test_data):\n",
    "    if i > 3:\n",
    "        break\n",
    "    # Tenemos una oración en sentence\n",
    "    #print('{}'.format(sentence))\n",
    "    #fasttext_data.write('{}\\n'.format(normalize(sentence)))\n",
    "    print(sentence[:-1]) # removing \\n at the end\n",
    "    label, prob = model.predict(sentence[:-1], k=3)\n",
    "    print('Category: {}\\nProb: {}'.format(label[0][9:], prob))\n",
    "    print(label)\n",
    "    print()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:16:01.335293Z",
     "start_time": "2019-08-01T17:16:01.325828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data succesfully loaded.\n",
      "\n",
      "pairID,gold_label\n",
      "2677109430.jpg#1r1n,contradiction\n",
      "2677109430.jpg#1r1e,neutral\n",
      "2677109430.jpg#1r1c,entailment\n",
      "6160193920.jpg#4r1n,neutral\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_data = open(fasttext_test_data_dir, 'r')\n",
    "    fasttext_test_data_pair_id_dir = './data.test.pair_id.txt'\n",
    "    test_data_pair_id = open(fasttext_test_data_pair_id_dir, 'r')\n",
    "    print('Test data succesfully loaded.')\n",
    "except IOError:\n",
    "    print('Test data not found.')\n",
    "\n",
    "print()\n",
    "header = 'pairID,gold_label'\n",
    "print(header)\n",
    "i=0\n",
    "for pairid, sentence in zip(test_data_pair_id, test_data):\n",
    "    if i > 3:\n",
    "        break\n",
    "    # Tenemos una oración en sentence\n",
    "    #print('{}'.format(sentence))\n",
    "    #fasttext_data.write('{}\\n'.format(normalize(sentence)))\n",
    "    label, prob = model.predict(sentence[:-1], k=1)\n",
    "    print('{},{}'.format(pairid[:-1], label[0][9:]))\n",
    "\n",
    "    i+=1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de archivo para subida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:18:48.498130Z",
     "start_time": "2019-08-02T12:18:47.952359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data succesfully loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_data = open(fasttext_test_data_dir, 'r')\n",
    "    fasttext_test_data_pair_id_dir = './data.test.pair_id.txt'\n",
    "    test_data_pair_id = open(fasttext_test_data_pair_id_dir, 'r')\n",
    "    print('Test data succesfully loaded.')\n",
    "except IOError:\n",
    "    print('Test data not found.')\n",
    "\n",
    "print()\n",
    "i=0\n",
    "test_solved = open('test_solved.csv', 'a')\n",
    "header = 'pairID,gold_label\\n'\n",
    "test_solved.write(header)\n",
    "for pairid, sentence in zip(test_data_pair_id, test_data):\n",
    "    # Tenemos una oración en sentence\n",
    "    #print('{}'.format(sentence))\n",
    "    #fasttext_data.write('{}\\n'.format(normalize(sentence)))\n",
    "    label, prob = model.predict(sentence[:-1], k=1)\n",
    "    test_solved.write('{},{}\\n'.format(pairid[:-1], label[0][9:]))\n",
    "    pass\n",
    "test_solved.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:57:20.990748Z",
     "start_time": "2019-07-30T03:57:20.978502Z"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "Hierarchical Softmax\n",
    "https://www.youtube.com/watch?v=B95LTf2rVWM\n",
    "\n",
    "Fasttext documentation\n",
    "https://github.com/facebookresearch/fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "375.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
